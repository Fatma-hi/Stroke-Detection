{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------Stroke_Detectors_Data_Modeling_&_Evaluation-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>age</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.706375</td>\n",
       "      <td>1.066746</td>\n",
       "      <td>1.051434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.121559</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.786070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>0.506346</td>\n",
       "      <td>1.626390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.437358</td>\n",
       "      <td>0.766044</td>\n",
       "      <td>0.255342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.501184</td>\n",
       "      <td>-0.655458</td>\n",
       "      <td>1.582163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  hypertension  heart_disease  work_type  Residence_type  \\\n",
       "0       1             0              1          2               1   \n",
       "1       0             0              0          3               0   \n",
       "2       1             0              1          2               0   \n",
       "3       0             0              0          2               1   \n",
       "4       0             1              0          3               0   \n",
       "\n",
       "   smoking_status  avg_glucose_level       bmi       age  stroke  \n",
       "0               1           2.706375  1.066746  1.051434       1  \n",
       "1               2           2.121559  0.013363  0.786070       1  \n",
       "2               2          -0.005028  0.506346  1.626390       1  \n",
       "3               3           1.437358  0.766044  0.255342       1  \n",
       "4               2           1.501184 -0.655458  1.582163       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(action='ignore')#for Ignoring warnings if any generated\n",
    "df = pd.read_csv('Preprocessed_Stroke_Detector_Dataset.csv')#Reading the Dataset\n",
    "df.head()#Displaying first 5 rows of the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['stroke'], axis=1)\n",
    "y=df['stroke']\n",
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state= 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models to be trained: decision tree, logistic regression, random forest, support vector machine, k nearest neighbor, naive bayes, and k means clustering.\n",
    "## We will compare the results obtained from training these models and report the one with the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model fitting completed.\n",
      "fit_time          0.03\n",
      "score_time        0.02\n",
      "test_accuracy     0.91\n",
      "test_precision    0.14\n",
      "test_recall       0.19\n",
      "test_f1           0.16\n",
      "dtype: float64\n",
      "Logistic Regression model fitting completed.\n",
      "fit_time          0.03\n",
      "score_time        0.01\n",
      "test_accuracy     0.95\n",
      "test_precision    0.10\n",
      "test_recall       0.01\n",
      "test_f1           0.01\n",
      "dtype: float64\n",
      "Random Forest model fitting completed.\n",
      "fit_time          1.08\n",
      "score_time        0.05\n",
      "test_accuracy     0.95\n",
      "test_precision    0.12\n",
      "test_recall       0.02\n",
      "test_f1           0.04\n",
      "dtype: float64\n",
      "Support Vector Machine model fitting completed.\n",
      "fit_time          0.31\n",
      "score_time        0.05\n",
      "test_accuracy     0.92\n",
      "test_precision    0.13\n",
      "test_recall       0.08\n",
      "test_f1           0.10\n",
      "dtype: float64\n",
      "K Nearest Neighbor model fitting completed.\n",
      "fit_time          0.02\n",
      "score_time        0.07\n",
      "test_accuracy     0.95\n",
      "test_precision    0.18\n",
      "test_recall       0.02\n",
      "test_f1           0.03\n",
      "dtype: float64\n",
      "Naive Bayes model fitting completed.\n",
      "fit_time          0.02\n",
      "score_time        0.02\n",
      "test_accuracy     0.88\n",
      "test_precision    0.18\n",
      "test_recall       0.42\n",
      "test_f1           0.25\n",
      "dtype: float64\n",
      "KMeans model fitting completed.\n",
      "fit_time          0.90\n",
      "score_time        0.40\n",
      "test_accuracy     0.60\n",
      "test_precision    0.02\n",
      "test_recall       0.29\n",
      "test_f1           0.03\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "models = dict()\n",
    "models['Decision Tree'] = DecisionTreeClassifier()\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "models['Support Vector Machine'] = SVC(kernel = 'sigmoid', gamma='scale')\n",
    "models['K Nearest Neighbor'] = KNeighborsClassifier()\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "models['KMeans'] = KMeans(n_clusters=2, n_init=10, random_state=42)\n",
    "scores2=[]\n",
    "for model in models:\n",
    "    models[model].fit(x_train, y_train)\n",
    "    print(model + \" model fitting completed.\")\n",
    "    scores = cross_validate(models[model], x_train, y_train, scoring = ['accuracy', 'precision','recall','f1'], cv = 10)\n",
    "    # scores2.append(scores)\n",
    "    df_scores = pd.DataFrame(scores, index = range(1,11))\n",
    "    #df_scores\n",
    "    print(df_scores.mean().round(2))\n",
    "    scores2.append(df_scores.mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below, we will  test each model and generate confusion matrix for each model to see the performance and evaluate how the prediction has worked for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "********************Decision Tree********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1218\n",
      "           1       0.20      0.23      0.21        60\n",
      "\n",
      "    accuracy                           0.92      1278\n",
      "   macro avg       0.58      0.59      0.59      1278\n",
      "weighted avg       0.93      0.92      0.92      1278\n",
      "\n",
      "********************Logistic Regression********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      1218\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.95      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.95      0.93      1278\n",
      "\n",
      "********************Random Forest********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1218\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.95      1278\n",
      "   macro avg       0.48      0.50      0.49      1278\n",
      "weighted avg       0.91      0.95      0.93      1278\n",
      "\n",
      "********************Support Vector Machine********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      1218\n",
      "           1       0.05      0.03      0.04        60\n",
      "\n",
      "    accuracy                           0.92      1278\n",
      "   macro avg       0.50      0.50      0.50      1278\n",
      "weighted avg       0.91      0.92      0.92      1278\n",
      "\n",
      "********************K Nearest Neighbor********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      1218\n",
      "           1       0.11      0.02      0.03        60\n",
      "\n",
      "    accuracy                           0.95      1278\n",
      "   macro avg       0.53      0.51      0.50      1278\n",
      "weighted avg       0.91      0.95      0.93      1278\n",
      "\n",
      "********************Naive Bayes********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      1218\n",
      "           1       0.13      0.28      0.18        60\n",
      "\n",
      "    accuracy                           0.88      1278\n",
      "   macro avg       0.55      0.59      0.56      1278\n",
      "weighted avg       0.92      0.88      0.90      1278\n",
      "\n",
      "********************KMeans********************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.86      1218\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.76      1278\n",
      "   macro avg       0.47      0.40      0.43      1278\n",
      "weighted avg       0.90      0.76      0.82      1278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\\n\")\n",
    "conf_matrix=[]\n",
    "for x in models:\n",
    "    print('*'*20+x+'*'*20)\n",
    "    model = models[x]\n",
    "    y_pred = model.predict(x_test)\n",
    "    arg_test = {'y_true':y_test, 'y_pred':y_pred}\n",
    "    conf_matrix.append(confusion_matrix(**arg_test))\n",
    "    print(classification_report(**arg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix for Each Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for  Decision Tree Model :\n",
      " [[1161   57]\n",
      " [  46   14]]\n",
      "Confusion Matrix for  Logistic Regression Model :\n",
      " [[1217    1]\n",
      " [  60    0]]\n",
      "Confusion Matrix for  Random Forest Model :\n",
      " [[1215    3]\n",
      " [  60    0]]\n",
      "Confusion Matrix for  Support Vector Machine Model :\n",
      " [[1177   41]\n",
      " [  58    2]]\n",
      "Confusion Matrix for  K Nearest Neighbor Model :\n",
      " [[1210    8]\n",
      " [  59    1]]\n",
      "Confusion Matrix for  Naive Bayes Model :\n",
      " [[1103  115]\n",
      " [  43   17]]\n",
      "Confusion Matrix for  KMeans :\n",
      " [[970 248]\n",
      " [ 60   0]]\n"
     ]
    }
   ],
   "source": [
    "model_names=[\"Decision Tree Model\",\"Logistic Regression Model\",\"Random Forest Model\",\"Support Vector Machine Model\",\"K Nearest Neighbor Model\",\"Naive Bayes Model\",\"KMeans\"]\n",
    "for i in range(7):\n",
    "    print(\"Confusion Matrix for \",model_names[i],\":\\n\", conf_matrix[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating four additional evaluation metrics which are not implemented using standard libraries.(Extra Credit Work)\n",
    "## Calculating F1-Score for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Model  Decision Tree Model = 0.16\n",
      "F1 Score for Model  Logistic Regression Model = 0.02\n",
      "F1 Score for Model  Random Forest Model = 0.03\n",
      "F1 Score for Model  Support Vector Machine Model = 0.1\n",
      "F1 Score for Model  K Nearest Neighbor Model = 0.04\n",
      "F1 Score for Model  Naive Bayes Model = 0.25\n",
      "F1 Score for Model  KMeans = 0.04\n"
     ]
    }
   ],
   "source": [
    "# F1_Score=2*(Precision*Recall)/(Precision+Recall)\n",
    "for i in range(7):\n",
    "    F1_Score=2*((scores2[i][3]*scores2[i][4])/(scores2[i][3]+scores2[i][4]))\n",
    "    print(\"F1 Score for Model \",model_names[i],\"=\",F1_Score.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Critical Success Index for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Success Index for Model  Decision Tree Model =  0.92\n",
      "Critical Success Index for Model  Logistic Regression Model =  0.95\n",
      "Critical Success Index for Model  Random Forest Model =  0.95\n",
      "Critical Success Index for Model  Support Vector Machine Model =  0.92\n",
      "Critical Success Index for Model  K Nearest Neighbor Model =  0.95\n",
      "Critical Success Index for Model  Naive Bayes Model =  0.87\n",
      "Critical Success Index for Model  KMeans =  0.76\n"
     ]
    }
   ],
   "source": [
    "# CSI=Hits/(Hits+Misses+FalseAlarms)\n",
    "for i in range(7):\n",
    "    CSI=(conf_matrix[i][0][0])/(conf_matrix[i][0][0]+conf_matrix[i][1][0]+conf_matrix[i][0][1])\n",
    "    print(\"Critical Success Index for Model \",model_names[i],\"= \",CSI.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating False Alarm Ratio for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Alarm Ratio for Model  Decision Tree Model =  0.05\n",
      "False Alarm Ratio for Model  Logistic Regression Model =  0.0\n",
      "False Alarm Ratio for Model  Random Forest Model =  0.0\n",
      "False Alarm Ratio for Model  Support Vector Machine Model =  0.03\n",
      "False Alarm Ratio for Model  K Nearest Neighbor Model =  0.01\n",
      "False Alarm Ratio for Model  Naive Bayes Model =  0.09\n",
      "False Alarm Ratio for Model  KMeans =  0.2\n"
     ]
    }
   ],
   "source": [
    "# FAR=FalseAlarms/(Hits+FalseAlarms)\n",
    "for i in range(7):\n",
    "    FAR=(conf_matrix[i][0][1])/(conf_matrix[i][0][0]+conf_matrix[i][0][1])\n",
    "    print(\"False Alarm Ratio for Model \",model_names[i],\"= \",FAR.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIAS Score Measure Ratio for Each Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIAS Score Measure Ratio for Model  Decision Tree Model =  1.01\n",
      "BIAS Score Measure Ratio for Model  Logistic Regression Model =  0.95\n",
      "BIAS Score Measure Ratio for Model  Random Forest Model =  0.96\n",
      "BIAS Score Measure Ratio for Model  Support Vector Machine Model =  0.99\n",
      "BIAS Score Measure Ratio for Model  K Nearest Neighbor Model =  0.96\n",
      "BIAS Score Measure Ratio for Model  Naive Bayes Model =  1.06\n",
      "BIAS Score Measure Ratio for Model  KMeans =  1.18\n"
     ]
    }
   ],
   "source": [
    "# BIAS=(Hits+FalseAlarms)/(Hits+Misses)\n",
    "for i in range(7):\n",
    "    BIAS=(conf_matrix[i][0][0]+conf_matrix[i][0][1])/(conf_matrix[i][0][0]+conf_matrix[i][1][0])\n",
    "    print(\"BIAS Score Measure Ratio for Model \",model_names[i],\"= \",BIAS.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the Accuracy Scores for Each Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Accuracy Score\n",
      "\n",
      "\n",
      "Decision Tree  Model:  92.0 %\n",
      "Logistic Regression  Model:  95.0 %\n",
      "Random Forest  Model:  95.0 %\n",
      "Support Vector Machine  Model:  92.0 %\n",
      "K Nearest Neighbor  Model:  95.0 %\n",
      "Naive Bayes  Model:  88.0 %\n",
      "KMeans  Model:  76.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Summary of Accuracy Score\\n\\n')\n",
    "for i in models:\n",
    "    model = models[i]\n",
    "    print(i,' Model: ',accuracy_score(y_test, model.predict(x_test)).round(2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy scores of the models indicate that logistic regression (95%), random forest (95%), and KNN (95%) have the highest accuracy scores. We can choose any of these models as our final model as they have a very good accuracy score. However, for this project we choose Logistic Regression and moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Cross Validating the Accuracy of Logistic Regression Model for cross validate value as 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [95.1 95.1 95.3 95.  95.3 95.  95.  95.  95.  95. ]\n",
      "Average cross-validation score: 95.1 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lgr=LogisticRegression()\n",
    "scores = cross_val_score(lgr, x_train, y_train, cv = 10, scoring='accuracy')\n",
    "\n",
    "print('Cross-validation scores:',scores.round(3)*100)\n",
    "print(\"Average cross-validation score:\",scores.mean().round(3)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for cross validation and resampling, we use mean cross validation. Cross validation indicates how our model will perform in the wild, and based on the cross validation scores obtained for this, our Logistic Regression model will perform with 95.1% accurately on average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Hyper-Parameter Optimization(Extra Credits):-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Using Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) For Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy Score:  95.0 %\n",
      "Best Hyperparameters:  {'C': 1, 'penalty': 'none', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "model = LogisticRegression()\n",
    "# define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = [1,2,3,4]\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(x_train,y_train)\n",
    "# summarize result\n",
    "print('Best Accuracy Score: ',result.best_score_.round(2)*100,\"%\")\n",
    "print('Best Hyperparameters: ',result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) For Support Vector Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy Score:  95.0 %\n",
      "Best Hyperparameters:  {'C': 1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1,2,3,4]}\n",
    "svc = SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(x_train,y_train)\n",
    "print('Best Accuracy Score: ',clf.best_score_.round(2)*100,\"%\")\n",
    "print('Best Hyperparameters: ',clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) For K Nearest Neighbor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy Score:  95.0 %\n",
      "Best Hyperparameters:  {'n_neighbors': 4}\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_neighbors': [1,2,3,4],\n",
    "}\n",
    "clf = KNeighborsClassifier()\n",
    "grid = GridSearchCV(clf, rf_params, cv=10, scoring='accuracy')\n",
    "grid.fit(x_train, y_train)\n",
    "print('Best Accuracy Score: ',grid.best_score_.round(2)*100,\"%\")\n",
    "print('Best Hyperparameters: ',grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-optimize in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-optimize) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-optimize) (1.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-optimize) (21.10.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-optimize) (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\khatr\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\khatr\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using BayesSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator:  RandomForestClassifier(criterion='entropy', max_depth=16, min_samples_leaf=11,\n",
      "                       n_estimators=47, random_state=80)\n",
      "Best Accuracy Score:  95.0 %\n",
      "Best Hyperparameters:  OrderedDict([('criterion', 'entropy'), ('max_depth', 16), ('min_samples_leaf', 11), ('min_samples_split', 2), ('n_estimators', 47)])\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV \n",
    "from skopt.space import Integer\n",
    "# Define the hyperparameter configuration space\n",
    "rf_params = {\n",
    "    'n_estimators': Integer(10,100),\n",
    "    'max_depth': Integer(5,50),\n",
    "    \"min_samples_split\":Integer(2,11),\n",
    "    \"min_samples_leaf\":Integer(1,11),\n",
    "    \"criterion\":['gini','entropy']\n",
    "}\n",
    "clf = RandomForestClassifier(random_state=80)\n",
    "Bayes = BayesSearchCV(clf, rf_params,cv=10,n_iter=1, n_jobs=1,scoring='accuracy')\n",
    "#number of iterations is set to 20, you can increase this number if time permits\n",
    "Bayes.fit(x_train,y_train)\n",
    "print(\"Best Estimator: \",Bayes.best_estimator_)\n",
    "print('Best Accuracy Score: ',Bayes.best_score_.round(2)*100,\"%\")\n",
    "print('Best Hyperparameters: ',Bayes.best_params_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14564845c381784a15bd807e3e23f0ef67b134315eddd78b12a2abca30a7ee99"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
